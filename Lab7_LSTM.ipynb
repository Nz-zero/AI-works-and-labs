{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Training Deep Recurrent Neural Network - Part 2\n",
    "\n",
    "Nattapat Yuvasuta, 59070501028<br>\n",
    "Niti Buesamae, 590705010047ID2<br>\n",
    "\n",
    "**Note: Please name your file**\n",
    "\n",
    "## Lab Instruction - Language Modelling and Text Classification\n",
    "\n",
    "In this lab, you will learn to train a deep recurrent neural network using LSTM with the Keras library using the Tensorflow backend. Your task is to implement the natural language modelling and text generation.\n",
    "\n",
    "Select your favourite book from https://www.gutenberg.org/browse/scores/top and download it as a text file. Then, you will train your language model using RNN-LSTM. \n",
    "\n",
    "- Language model (in Thai): http://bit.ly/language_model_1\n",
    "- Tutorial on how to create a language model (in English): https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275\n",
    "\n",
    "To evaluate the model, the perplexity measurement is used: https://stats.stackexchange.com/questions/10302/what-is-perplexity\n",
    "\n",
    "Last, fine-tune your model. You have to try different hyperparameter or adding more data. Discuss your result.\n",
    "\n",
    "\n",
    "\n",
    "**The total lab score is 20 which will be evaluated as follows:**</br>\n",
    "1. Specification (Do as the instruction said. This include the model tuning section where you have to do a proper amount of tuning) - 10 points\n",
    "2. Design of logic (No weired things in the process) - 5 points\n",
    "3. Journaling (Communicate your thought process, comment your code, and discuss result & analyse **in every step**) - 5 points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Import require library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import require library\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "import keras.utils as ku \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file = open('data.txt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Preprocessing \n",
    "\n",
    "*Note that only story will be used as a dataset, footnote and creddit are not include.*\n",
    "\n",
    "The symbol '\\n' is indicated the end of the line ``<EOS>``, which is for our model to end the sentence here.\n",
    "\n",
    "To create a corpus for your model. The following code is can be used:</br>\n",
    "*Note that other techniques can be used*\n",
    "\n",
    "```python\n",
    "# cut the text in semi-redundant sequences of maxlen characters.\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "```\n",
    "\n",
    "The code loop through the data from first word to the last word. The maxlen define a next n word for a model to predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = [t.replace('\\n', '<EOS>') for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maxlen = 1\\nstep = 1\\nsentences = []\\nnext_chars= []'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''maxlen = 1\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars= []'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Preprocessing \\n# Create corpus & Word vectorization\\nfor i in range(0, len(text) - maxlen, step):\\n    sentences.append(text[i: i + maxlen])\\n    next_chars.append(text[i + maxlen])'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Preprocessing \n",
    "# Create corpus & Word vectorization\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation():\n",
    "    pass \n",
    "def create_model():\n",
    "    pass\n",
    "def generate_text():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "def dataset_preparation(data):\n",
    "    corpus = data.lower().split(\"\\n\")    \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences,   \n",
    "                          maxlen=max_sequence_len, padding='pre'))\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors,label,max_sequence_len,total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref:  https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Language Model\n",
    "\n",
    "Define RNN model using LSTM and word embedding representation</br>\n",
    "We will used perplexity as a metrics\n",
    "\n",
    "```python\n",
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = keras.backend.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = keras.backend.pow(2.0, cross_entropy)\n",
    "    return perplexity\n",
    "```\n",
    "\n",
    "To used custom metrics function > https://keras.io/metrics/\n",
    "\n",
    "For a loss function `categorical_crossentropy` is used, any optimzation method can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = keras.backend.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = keras.backend.pow(2.0, cross_entropy)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(predictors, label, max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 50, input_length=input_len))\n",
    "    model.add(LSTM(500))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['mae', 'acc',perplexity])\n",
    "    model.fit(predictors, label, epochs=50, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, max_len, total_words = dataset_preparation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Evaluate your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model using perplexity measurment (You can try adding other measurements as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96360/96360 [==============================] - 139s 1ms/step - loss: 6.3309 - mean_absolute_error: 2.4749e-04 - acc: 0.0648 - perplexity: 717.1919\n",
      "Epoch 2/50\n",
      "96360/96360 [==============================] - 136s 1ms/step - loss: 5.5622 - mean_absolute_error: 2.4254e-04 - acc: 0.1150 - perplexity: 396.1305\n",
      "Epoch 3/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 5.1207 - mean_absolute_error: 2.3899e-04 - acc: 0.1410 - perplexity: 232.7817\n",
      "Epoch 4/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 4.6973 - mean_absolute_error: 2.3560e-04 - acc: 0.1581 - perplexity: 136.9707\n",
      "Epoch 5/50\n",
      "96360/96360 [==============================] - 143s 1ms/step - loss: 4.1922 - mean_absolute_error: 2.3095e-04 - acc: 0.1906 - perplexity: 91.0966\n",
      "Epoch 6/50\n",
      "96360/96360 [==============================] - 145s 2ms/step - loss: 3.6430 - mean_absolute_error: 2.2228e-04 - acc: 0.2469 - perplexity: 68.3713\n",
      "Epoch 7/50\n",
      "96360/96360 [==============================] - 143s 1ms/step - loss: 3.1360 - mean_absolute_error: 2.0967e-04 - acc: 0.3226 - perplexity: 57.2786\n",
      "Epoch 8/50\n",
      "96360/96360 [==============================] - 142s 1ms/step - loss: 2.6986 - mean_absolute_error: 1.9496e-04 - acc: 0.4005 - perplexity: 50.5108\n",
      "Epoch 9/50\n",
      "96360/96360 [==============================] - 142s 1ms/step - loss: 2.3204 - mean_absolute_error: 1.7953e-04 - acc: 0.4754 - perplexity: 46.4394\n",
      "Epoch 10/50\n",
      "96360/96360 [==============================] - 144s 1ms/step - loss: 1.9970 - mean_absolute_error: 1.6374e-04 - acc: 0.5429 - perplexity: 42.7401\n",
      "Epoch 11/50\n",
      "96360/96360 [==============================] - 144s 1ms/step - loss: 1.7248 - mean_absolute_error: 1.4807e-04 - acc: 0.6023 - perplexity: 40.7609\n",
      "Epoch 12/50\n",
      "96360/96360 [==============================] - 145s 2ms/step - loss: 1.4992 - mean_absolute_error: 1.3352e-04 - acc: 0.6575 - perplexity: 39.2400\n",
      "Epoch 13/50\n",
      "96360/96360 [==============================] - 146s 2ms/step - loss: 1.3180 - mean_absolute_error: 1.2047e-04 - acc: 0.6984 - perplexity: 38.2218\n",
      "Epoch 14/50\n",
      "96360/96360 [==============================] - 147s 2ms/step - loss: 1.1791 - mean_absolute_error: 1.0962e-04 - acc: 0.7302 - perplexity: 37.3281 2s - loss: 1.1762 - mean_absolute_error: 1.0943e-04 - acc: 0.\n",
      "Epoch 15/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 1.0691 - mean_absolute_error: 1.0053e-04 - acc: 0.7556 - perplexity: 36.6792\n",
      "Epoch 16/50\n",
      "96360/96360 [==============================] - 139s 1ms/step - loss: 0.9829 - mean_absolute_error: 9.3164e-05 - acc: 0.7743 - perplexity: 36.3376\n",
      "Epoch 17/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 0.9240 - mean_absolute_error: 8.7633e-05 - acc: 0.7858 - perplexity: 35.8101\n",
      "Epoch 18/50\n",
      "96360/96360 [==============================] - 140s 1ms/step - loss: 0.8679 - mean_absolute_error: 8.2509e-05 - acc: 0.7981 - perplexity: 35.5801\n",
      "Epoch 19/50\n",
      "96360/96360 [==============================] - 139s 1ms/step - loss: 0.8310 - mean_absolute_error: 7.9058e-05 - acc: 0.8057 - perplexity: 35.3794\n",
      "Epoch 20/50\n",
      "96360/96360 [==============================] - 140s 1ms/step - loss: 0.8015 - mean_absolute_error: 7.6279e-05 - acc: 0.8102 - perplexity: 34.4287\n",
      "Epoch 21/50\n",
      "96360/96360 [==============================] - 144s 1ms/step - loss: 0.7771 - mean_absolute_error: 7.3884e-05 - acc: 0.8159 - perplexity: 34.7474\n",
      "Epoch 22/50\n",
      "96360/96360 [==============================] - 142s 1ms/step - loss: 0.7510 - mean_absolute_error: 7.1375e-05 - acc: 0.8194 - perplexity: 33.8429\n",
      "Epoch 23/50\n",
      "96360/96360 [==============================] - 150s 2ms/step - loss: 0.7405 - mean_absolute_error: 7.0095e-05 - acc: 0.8212 - perplexity: 33.7569\n",
      "Epoch 24/50\n",
      "96360/96360 [==============================] - 143s 1ms/step - loss: 0.7151 - mean_absolute_error: 6.7347e-05 - acc: 0.8279 - perplexity: 33.6007\n",
      "Epoch 25/50\n",
      "96360/96360 [==============================] - 145s 2ms/step - loss: 0.7134 - mean_absolute_error: 6.7520e-05 - acc: 0.8250 - perplexity: 33.9014\n",
      "Epoch 26/50\n",
      "96360/96360 [==============================] - 152s 2ms/step - loss: 0.6975 - mean_absolute_error: 6.5793e-05 - acc: 0.8284 - perplexity: 33.8974\n",
      "Epoch 27/50\n",
      "96360/96360 [==============================] - 153s 2ms/step - loss: 0.6936 - mean_absolute_error: 6.5445e-05 - acc: 0.8291 - perplexity: 33.2686\n",
      "Epoch 28/50\n",
      "96360/96360 [==============================] - 167s 2ms/step - loss: 0.6841 - mean_absolute_error: 6.4211e-05 - acc: 0.8294 - perplexity: 33.5955\n",
      "Epoch 29/50\n",
      "96360/96360 [==============================] - 141s 1ms/step - loss: 0.6838 - mean_absolute_error: 6.4090e-05 - acc: 0.8285 - perplexity: 33.2256\n",
      "Epoch 30/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6784 - mean_absolute_error: 6.3425e-05 - acc: 0.8295 - perplexity: 33.4148\n",
      "Epoch 31/50\n",
      "96360/96360 [==============================] - 141s 1ms/step - loss: 0.6657 - mean_absolute_error: 6.2068e-05 - acc: 0.8335 - perplexity: 33.3949\n",
      "Epoch 32/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 0.6607 - mean_absolute_error: 6.1722e-05 - acc: 0.8335 - perplexity: 33.1693\n",
      "Epoch 33/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6616 - mean_absolute_error: 6.1182e-05 - acc: 0.8323 - perplexity: 33.1633\n",
      "Epoch 34/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6516 - mean_absolute_error: 6.0543e-05 - acc: 0.8347 - perplexity: 32.6735\n",
      "Epoch 35/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6534 - mean_absolute_error: 6.0414e-05 - acc: 0.8351 - perplexity: 32.4017 1s - loss: 0.6517 - mean_absolute_error: 6.0298e-05 - acc: 0.8355 - pe\n",
      "Epoch 36/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 0.6500 - mean_absolute_error: 6.0194e-05 - acc: 0.8336 - perplexity: 32.2790\n",
      "Epoch 37/50\n",
      "96360/96360 [==============================] - 136s 1ms/step - loss: 0.6414 - mean_absolute_error: 5.9584e-05 - acc: 0.8356 - perplexity: 32.4177\n",
      "Epoch 38/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6475 - mean_absolute_error: 5.9561e-05 - acc: 0.8332 - perplexity: 33.0483\n",
      "Epoch 39/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6476 - mean_absolute_error: 5.9633e-05 - acc: 0.8333 - perplexity: 32.7975\n",
      "Epoch 40/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6449 - mean_absolute_error: 5.9338e-05 - acc: 0.8336 - perplexity: 33.1239\n",
      "Epoch 41/50\n",
      "96360/96360 [==============================] - 135s 1ms/step - loss: 0.6476 - mean_absolute_error: 5.9512e-05 - acc: 0.8321 - perplexity: 32.3891\n",
      "Epoch 42/50\n",
      "96360/96360 [==============================] - 135s 1ms/step - loss: 0.6387 - mean_absolute_error: 5.8581e-05 - acc: 0.8342 - perplexity: 32.2624\n",
      "Epoch 43/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6494 - mean_absolute_error: 5.9820e-05 - acc: 0.8305 - perplexity: 32.5263\n",
      "Epoch 44/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 0.6519 - mean_absolute_error: 5.9704e-05 - acc: 0.8297 - perplexity: 32.9394\n",
      "Epoch 45/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 0.6557 - mean_absolute_error: 6.0408e-05 - acc: 0.8270 - perplexity: 32.9528\n",
      "Epoch 46/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6450 - mean_absolute_error: 5.9154e-05 - acc: 0.8308 - perplexity: 32.6155\n",
      "Epoch 47/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 0.6406 - mean_absolute_error: 5.8760e-05 - acc: 0.8317 - perplexity: 32.2990 3s - loss: 0.6369 - mean_absolute_error: 5.85\n",
      "Epoch 48/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6474 - mean_absolute_error: 5.9384e-05 - acc: 0.8304 - perplexity: 32.3938\n",
      "Epoch 49/50\n",
      "96360/96360 [==============================] - 137s 1ms/step - loss: 0.6558 - mean_absolute_error: 5.9701e-05 - acc: 0.8287 - perplexity: 33.4316\n",
      "Epoch 50/50\n",
      "96360/96360 [==============================] - 138s 1ms/step - loss: 0.6476 - mean_absolute_error: 5.9255e-05 - acc: 0.8299 - perplexity: 32.5448\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X, Y, max_len, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Text generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def generate_text(seed_text, max_sequence_len, tolenizer):\n",
    "    # Loop through the next n words\n",
    "    for _ in range(200):\n",
    "        # Preprecess your seed_text and predict the output\n",
    "        # ======\n",
    "        # Add your code here\n",
    "        # ======\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            # convert word vector representation to a word string\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "        if \n",
    "    return seed_text'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, max_sequence_len, model):\n",
    "    for j in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen= \n",
    "                             max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "  \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ref: https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate your sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne was sitting on the yellow chair by the window gazing mournfully out they morning under always then jane had to him up until her face led marilla’s dinner to the end of been led continued to the pond mercy of the hotel and the night at the house she gets good going to be it how got as i like when you are let me oh marilla i’m willing to think i didn’t know they’re myself but those don’t know i’d like have three head ” she said in a here it’s a chair you can come along isn’t it\n"
     ]
    }
   ],
   "source": [
    "text = generate_text(\"Anne\", 100, max_len, model)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model Tuning \n",
    "\n",
    "Write down why you design this architecture or why you choose this set of parameter</br>\n",
    "You should have at least 1 different architectures/set of hyperparameters per person in your team</br>\n",
    "Last, train your best performed model **on 50 epoch** (or you can try 100 epoch but this will take time)</br>\n",
    "*Note: For the last step, please turn off a verbose during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out different hyperparameter & model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tuning #1 \n",
    "try to use bidirectional rnns that we learn from previuos work (midterm paper) use with LSTM. We think will produce a better result\n",
    "\n",
    "ref: https://keras.io/layers/wrappers/ <br>\n",
    "     https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1(predictors, label, max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1   \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 50, input_length=input_len))\n",
    "    model.add(Bidirectional(LSTM(200,return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['mae', 'acc',perplexity])\n",
    "    model.fit(predictors, label, epochs=50, verbose=1)\n",
    "    model.save('model1.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96360/96360 [==============================] - 299s 3ms/step - loss: 6.6928 - mean_absolute_error: 2.4945e-04 - acc: 0.0367 - perplexity: 699.9005\n",
      "Epoch 2/50\n",
      "96360/96360 [==============================] - 293s 3ms/step - loss: 6.4023 - mean_absolute_error: 2.4894e-04 - acc: 0.0451 - perplexity: 544.1216\n",
      "Epoch 3/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 6.2466 - mean_absolute_error: 2.4846e-04 - acc: 0.0529 - perplexity: 481.9432\n",
      "Epoch 4/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 6.0485 - mean_absolute_error: 2.4764e-04 - acc: 0.0668 - perplexity: 392.6221\n",
      "Epoch 5/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 5.8775 - mean_absolute_error: 2.4660e-04 - acc: 0.0831 - perplexity: 335.3727\n",
      "Epoch 6/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 5.7278 - mean_absolute_error: 2.4545e-04 - acc: 0.0942 - perplexity: 285.3171\n",
      "Epoch 7/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 5.5880 - mean_absolute_error: 2.4420e-04 - acc: 0.1035 - perplexity: 266.3676\n",
      "Epoch 8/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 5.4732 - mean_absolute_error: 2.4320e-04 - acc: 0.1100 - perplexity: 251.2760\n",
      "Epoch 9/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 5.3716 - mean_absolute_error: 2.4231e-04 - acc: 0.1156 - perplexity: 237.2425\n",
      "Epoch 10/50\n",
      "96360/96360 [==============================] - 287s 3ms/step - loss: 5.2839 - mean_absolute_error: 2.4143e-04 - acc: 0.1210 - perplexity: 220.2087\n",
      "Epoch 11/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 5.2092 - mean_absolute_error: 2.4057e-04 - acc: 0.1255 - perplexity: 212.0850\n",
      "Epoch 12/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 5.1383 - mean_absolute_error: 2.3971e-04 - acc: 0.1318 - perplexity: 202.4606\n",
      "Epoch 13/50\n",
      "96360/96360 [==============================] - 287s 3ms/step - loss: 5.0762 - mean_absolute_error: 2.3882e-04 - acc: 0.1361 - perplexity: 194.8375\n",
      "Epoch 14/50\n",
      "96360/96360 [==============================] - 290s 3ms/step - loss: 5.0171 - mean_absolute_error: 2.3807e-04 - acc: 0.1398 - perplexity: 188.9132\n",
      "Epoch 15/50\n",
      "96360/96360 [==============================] - 286s 3ms/step - loss: 4.9618 - mean_absolute_error: 2.3731e-04 - acc: 0.1439 - perplexity: 188.3291\n",
      "Epoch 16/50\n",
      "96360/96360 [==============================] - 287s 3ms/step - loss: 4.9067 - mean_absolute_error: 2.3656e-04 - acc: 0.1472 - perplexity: 177.8017\n",
      "Epoch 17/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 4.8545 - mean_absolute_error: 2.3576e-04 - acc: 0.1525 - perplexity: 177.8920\n",
      "Epoch 18/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 4.8005 - mean_absolute_error: 2.3499e-04 - acc: 0.1565 - perplexity: 174.1145\n",
      "Epoch 19/50\n",
      "96360/96360 [==============================] - 287s 3ms/step - loss: 4.7549 - mean_absolute_error: 2.3439e-04 - acc: 0.1606 - perplexity: 167.7917\n",
      "Epoch 20/50\n",
      "96360/96360 [==============================] - 290s 3ms/step - loss: 4.7056 - mean_absolute_error: 2.3353e-04 - acc: 0.1640 - perplexity: 168.2836\n",
      "Epoch 21/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 4.6581 - mean_absolute_error: 2.3276e-04 - acc: 0.1669 - perplexity: 165.0909\n",
      "Epoch 22/50\n",
      "96360/96360 [==============================] - 287s 3ms/step - loss: 4.6148 - mean_absolute_error: 2.3209e-04 - acc: 0.1719 - perplexity: 165.1567\n",
      "Epoch 23/50\n",
      "96360/96360 [==============================] - 287s 3ms/step - loss: 4.5685 - mean_absolute_error: 2.3140e-04 - acc: 0.1757 - perplexity: 163.9046\n",
      "Epoch 24/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 4.5230 - mean_absolute_error: 2.3045e-04 - acc: 0.1809 - perplexity: 158.0254\n",
      "Epoch 25/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 4.4768 - mean_absolute_error: 2.2981e-04 - acc: 0.1842 - perplexity: 154.6204\n",
      "Epoch 26/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 4.4377 - mean_absolute_error: 2.2914e-04 - acc: 0.1868 - perplexity: 158.4902\n",
      "Epoch 27/50\n",
      "96360/96360 [==============================] - 293s 3ms/step - loss: 4.3943 - mean_absolute_error: 2.2848e-04 - acc: 0.1899 - perplexity: 152.3873\n",
      "Epoch 28/50\n",
      "96360/96360 [==============================] - 316s 3ms/step - loss: 4.3550 - mean_absolute_error: 2.2775e-04 - acc: 0.1945 - perplexity: 154.9671\n",
      "Epoch 29/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 4.3113 - mean_absolute_error: 2.2690e-04 - acc: 0.1994 - perplexity: 154.3379\n",
      "Epoch 30/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 4.2719 - mean_absolute_error: 2.2630e-04 - acc: 0.2021 - perplexity: 154.6731\n",
      "Epoch 31/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 4.2306 - mean_absolute_error: 2.2538e-04 - acc: 0.2074 - perplexity: 152.6153\n",
      "Epoch 32/50\n",
      "96360/96360 [==============================] - 289s 3ms/step - loss: 4.1890 - mean_absolute_error: 2.2473e-04 - acc: 0.2105 - perplexity: 155.6550\n",
      "Epoch 33/50\n",
      "96360/96360 [==============================] - 290s 3ms/step - loss: 4.1587 - mean_absolute_error: 2.2400e-04 - acc: 0.2147 - perplexity: 151.3570\n",
      "Epoch 34/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 4.1217 - mean_absolute_error: 2.2336e-04 - acc: 0.2170 - perplexity: 147.5032\n",
      "Epoch 35/50\n",
      "96360/96360 [==============================] - 288s 3ms/step - loss: 4.0831 - mean_absolute_error: 2.2247e-04 - acc: 0.2206 - perplexity: 151.8978\n",
      "Epoch 36/50\n",
      "96360/96360 [==============================] - 292s 3ms/step - loss: 4.0516 - mean_absolute_error: 2.2179e-04 - acc: 0.2246 - perplexity: 149.8919\n",
      "Epoch 37/50\n",
      "96360/96360 [==============================] - 291s 3ms/step - loss: 4.0132 - mean_absolute_error: 2.2119e-04 - acc: 0.2280 - perplexity: 146.9264\n",
      "Epoch 38/50\n",
      "96360/96360 [==============================] - 290s 3ms/step - loss: 3.9783 - mean_absolute_error: 2.2026e-04 - acc: 0.2323 - perplexity: 149.0164\n",
      "Epoch 39/50\n",
      "96360/96360 [==============================] - 292s 3ms/step - loss: 3.9502 - mean_absolute_error: 2.1985e-04 - acc: 0.2340 - perplexity: 142.5448\n",
      "Epoch 40/50\n",
      "96360/96360 [==============================] - 294s 3ms/step - loss: 3.9203 - mean_absolute_error: 2.1906e-04 - acc: 0.2381 - perplexity: 146.6251\n",
      "Epoch 41/50\n",
      "96360/96360 [==============================] - 291s 3ms/step - loss: 3.8814 - mean_absolute_error: 2.1818e-04 - acc: 0.2418 - perplexity: 145.0075\n",
      "Epoch 42/50\n",
      "96360/96360 [==============================] - 292s 3ms/step - loss: 3.8559 - mean_absolute_error: 2.1749e-04 - acc: 0.2462 - perplexity: 143.9241\n",
      "Epoch 43/50\n",
      "96360/96360 [==============================] - 291s 3ms/step - loss: 3.8256 - mean_absolute_error: 2.1693e-04 - acc: 0.2493 - perplexity: 144.0703\n",
      "Epoch 44/50\n",
      "96360/96360 [==============================] - 292s 3ms/step - loss: 3.8024 - mean_absolute_error: 2.1647e-04 - acc: 0.2486 - perplexity: 139.4861\n",
      "Epoch 45/50\n",
      "96360/96360 [==============================] - 294s 3ms/step - loss: 3.7705 - mean_absolute_error: 2.1568e-04 - acc: 0.2537 - perplexity: 148.7029\n",
      "Epoch 46/50\n",
      "96360/96360 [==============================] - 292s 3ms/step - loss: 3.7427 - mean_absolute_error: 2.1502e-04 - acc: 0.2569 - perplexity: 149.9036\n",
      "Epoch 47/50\n",
      "96360/96360 [==============================] - 293s 3ms/step - loss: 3.7153 - mean_absolute_error: 2.1433e-04 - acc: 0.2605 - perplexity: 144.4414\n",
      "Epoch 48/50\n",
      "96360/96360 [==============================] - 293s 3ms/step - loss: 3.6907 - mean_absolute_error: 2.1365e-04 - acc: 0.2635 - perplexity: 140.9352\n",
      "Epoch 49/50\n",
      "96360/96360 [==============================] - 293s 3ms/step - loss: 3.6678 - mean_absolute_error: 2.1312e-04 - acc: 0.2667 - perplexity: 142.1498\n",
      "Epoch 50/50\n",
      "96360/96360 [==============================] - 295s 3ms/step - loss: 3.6510 - mean_absolute_error: 2.1262e-04 - acc: 0.2679 - perplexity: 141.3613\n"
     ]
    }
   ],
   "source": [
    "model1 = create_model1(X, Y, max_len, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne had been a little sigh of delight was a little little was and willowmere and the brook of the slope and and she and to run in and a and who and i have to and have a thing to have to come to never a of is a white little wood and all it was a very sigh she was the face from the fiddlesticks and at the brook of them for to me i never ” said marilla of that she said to do a very sigh her and if she was fond of that she ” said\n"
     ]
    }
   ],
   "source": [
    "text1 = generate_text(\"Anne\", 100, max_len, model1)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of model1 // tuning BLSTM\n",
    "from observation we found that a perplexity could be lower if we use more epoach on training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tuning #2  \n",
    "from previos model we found that BLSTM is not good so we stick to the original model and improved it by increase droupout layer to 0.5 . we think it might clean some non-important word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(predictors, label, max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 50, input_length=input_len))\n",
    "    model.add(LSTM(500))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['mae', 'acc',perplexity])\n",
    "    model.fit(predictors, label, epochs=50, verbose=1)\n",
    "    model.save('model2.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96360/96360 [==============================] - 202s 2ms/step - loss: 6.4376 - mean_absolute_error: 2.4853e-04 - acc: 0.0510 - perplexity: 524.6706\n",
      "Epoch 2/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 5.9084 - mean_absolute_error: 2.4500e-04 - acc: 0.0944 - perplexity: 597.8566\n",
      "Epoch 3/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 5.5489 - mean_absolute_error: 2.4149e-04 - acc: 0.1222 - perplexity: 599.5734\n",
      "Epoch 4/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 5.3063 - mean_absolute_error: 2.3907e-04 - acc: 0.1374 - perplexity: 552.4178\n",
      "Epoch 5/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 5.1026 - mean_absolute_error: 2.3682e-04 - acc: 0.1512 - perplexity: 485.7329\n",
      "Epoch 6/50\n",
      "96360/96360 [==============================] - 202s 2ms/step - loss: 4.9027 - mean_absolute_error: 2.3451e-04 - acc: 0.1635 - perplexity: 436.2815\n",
      "Epoch 7/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 4.7048 - mean_absolute_error: 2.3216e-04 - acc: 0.1763 - perplexity: 376.6032\n",
      "Epoch 8/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 4.4909 - mean_absolute_error: 2.2948e-04 - acc: 0.1904 - perplexity: 318.8915\n",
      "Epoch 9/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 4.2779 - mean_absolute_error: 2.2672e-04 - acc: 0.2053 - perplexity: 279.7100\n",
      "Epoch 10/50\n",
      "96360/96360 [==============================] - 203s 2ms/step - loss: 4.0710 - mean_absolute_error: 2.2345e-04 - acc: 0.2242 - perplexity: 243.5223\n",
      "Epoch 11/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 3.8550 - mean_absolute_error: 2.1965e-04 - acc: 0.2443 - perplexity: 229.0592\n",
      "Epoch 12/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 3.6712 - mean_absolute_error: 2.1608e-04 - acc: 0.2647 - perplexity: 204.0954\n",
      "Epoch 13/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 3.4759 - mean_absolute_error: 2.1152e-04 - acc: 0.2886 - perplexity: 191.9577\n",
      "Epoch 14/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 3.3141 - mean_absolute_error: 2.0739e-04 - acc: 0.3125 - perplexity: 180.6040\n",
      "Epoch 15/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 3.1565 - mean_absolute_error: 2.0303e-04 - acc: 0.3338 - perplexity: 175.0405\n",
      "Epoch 16/50\n",
      "96360/96360 [==============================] - 202s 2ms/step - loss: 3.0250 - mean_absolute_error: 1.9894e-04 - acc: 0.3525 - perplexity: 168.2509\n",
      "Epoch 17/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 2.8948 - mean_absolute_error: 1.9475e-04 - acc: 0.3720 - perplexity: 161.5907\n",
      "Epoch 18/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 2.7912 - mean_absolute_error: 1.9081e-04 - acc: 0.3898 - perplexity: 159.6397\n",
      "Epoch 19/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 2.6955 - mean_absolute_error: 1.8741e-04 - acc: 0.4045 - perplexity: 152.1107\n",
      "Epoch 20/50\n",
      "96360/96360 [==============================] - 202s 2ms/step - loss: 2.6063 - mean_absolute_error: 1.8407e-04 - acc: 0.4184 - perplexity: 151.9517\n",
      "Epoch 21/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 2.5205 - mean_absolute_error: 1.8033e-04 - acc: 0.4343 - perplexity: 150.5889\n",
      "Epoch 22/50\n",
      "96360/96360 [==============================] - 198s 2ms/step - loss: 2.4510 - mean_absolute_error: 1.7759e-04 - acc: 0.4464 - perplexity: 145.75411s - loss: 2.4488 - mean_abs\n",
      "Epoch 23/50\n",
      "96360/96360 [==============================] - 198s 2ms/step - loss: 2.3860 - mean_absolute_error: 1.7463e-04 - acc: 0.4585 - perplexity: 142.4650\n",
      "Epoch 24/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 2.3226 - mean_absolute_error: 1.7186e-04 - acc: 0.4693 - perplexity: 141.9625\n",
      "Epoch 25/50\n",
      "96360/96360 [==============================] - 201s 2ms/step - loss: 2.2667 - mean_absolute_error: 1.6895e-04 - acc: 0.4829 - perplexity: 140.9297\n",
      "Epoch 26/50\n",
      "96360/96360 [==============================] - 198s 2ms/step - loss: 2.2264 - mean_absolute_error: 1.6724e-04 - acc: 0.4869 - perplexity: 141.3236\n",
      "Epoch 27/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 2.1732 - mean_absolute_error: 1.6480e-04 - acc: 0.4976 - perplexity: 136.8225\n",
      "Epoch 28/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 2.1313 - mean_absolute_error: 1.6273e-04 - acc: 0.5040 - perplexity: 136.3195\n",
      "Epoch 29/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 2.1064 - mean_absolute_error: 1.6135e-04 - acc: 0.5095 - perplexity: 136.3571\n",
      "Epoch 30/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 2.0724 - mean_absolute_error: 1.5952e-04 - acc: 0.5190 - perplexity: 135.1150\n",
      "Epoch 31/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 2.0213 - mean_absolute_error: 1.5736e-04 - acc: 0.5278 - perplexity: 133.4097\n",
      "Epoch 32/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 2.0053 - mean_absolute_error: 1.5600e-04 - acc: 0.5303 - perplexity: 133.4634\n",
      "Epoch 33/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 1.9824 - mean_absolute_error: 1.5503e-04 - acc: 0.5351 - perplexity: 134.5227\n",
      "Epoch 34/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 1.9460 - mean_absolute_error: 1.5313e-04 - acc: 0.5426 - perplexity: 132.0193\n",
      "Epoch 35/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 1.9309 - mean_absolute_error: 1.5206e-04 - acc: 0.5458 - perplexity: 133.0529\n",
      "Epoch 36/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 1.9103 - mean_absolute_error: 1.5115e-04 - acc: 0.5478 - perplexity: 132.6212\n",
      "Epoch 37/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 1.8795 - mean_absolute_error: 1.4934e-04 - acc: 0.5564 - perplexity: 132.0706\n",
      "Epoch 38/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 1.8676 - mean_absolute_error: 1.4882e-04 - acc: 0.5569 - perplexity: 133.1825\n",
      "Epoch 39/50\n",
      "96360/96360 [==============================] - 203s 2ms/step - loss: 1.8539 - mean_absolute_error: 1.4800e-04 - acc: 0.5595 - perplexity: 132.1553\n",
      "Epoch 40/50\n",
      "96360/96360 [==============================] - 200s 2ms/step - loss: 1.8362 - mean_absolute_error: 1.4685e-04 - acc: 0.5653 - perplexity: 132.6015\n",
      "Epoch 41/50\n",
      "96360/96360 [==============================] - 196s 2ms/step - loss: 1.8160 - mean_absolute_error: 1.4603e-04 - acc: 0.5684 - perplexity: 132.8359\n",
      "Epoch 42/50\n",
      "96360/96360 [==============================] - 197s 2ms/step - loss: 1.8078 - mean_absolute_error: 1.4544e-04 - acc: 0.5703 - perplexity: 129.0130\n",
      "Epoch 43/50\n",
      "96360/96360 [==============================] - 198s 2ms/step - loss: 1.7984 - mean_absolute_error: 1.4454e-04 - acc: 0.5732 - perplexity: 131.5656\n",
      "Epoch 44/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 1.7778 - mean_absolute_error: 1.4364e-04 - acc: 0.5780 - perplexity: 129.4230\n",
      "Epoch 45/50\n",
      "96360/96360 [==============================] - 198s 2ms/step - loss: 1.7661 - mean_absolute_error: 1.4269e-04 - acc: 0.5809 - perplexity: 128.7286\n",
      "Epoch 46/50\n",
      "96360/96360 [==============================] - 198s 2ms/step - loss: 1.7565 - mean_absolute_error: 1.4224e-04 - acc: 0.5808 - perplexity: 129.8051\n",
      "Epoch 47/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 1.7359 - mean_absolute_error: 1.4143e-04 - acc: 0.5831 - perplexity: 126.7910\n",
      "Epoch 48/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 1.7246 - mean_absolute_error: 1.4029e-04 - acc: 0.5910 - perplexity: 129.7689\n",
      "Epoch 49/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 1.7240 - mean_absolute_error: 1.4059e-04 - acc: 0.5874 - perplexity: 128.0635\n",
      "Epoch 50/50\n",
      "96360/96360 [==============================] - 199s 2ms/step - loss: 1.7212 - mean_absolute_error: 1.4049e-04 - acc: 0.5872 - perplexity: 129.3467\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model2(X, Y, max_len, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne was sitting on the yellow chair by the window gazing mournfully out of the spare room where the air was a great summer at the present when she was sure of the side of the house was you ” said anne with her arms “i see her a child was about that little and anyhow i thought it was too far to be the same friends i can i was the best of an heart with a boy in the day i left it and i was an orphan and and i had to go to school and do it\n"
     ]
    }
   ],
   "source": [
    "text2 = generate_text(\"Anne\", 100, max_len, model2)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of model2 // tuning Dropout\n",
    "from observation we found that it worsen the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tuning #3\n",
    "from previos model we found that add more dropout is not good \n",
    "so we have our last method which we add additional layer of LSTM it hope that it will capture more meaningful detail\n",
    "\n",
    "ref: https://machinelearningmastery.com/stacked-long-short-term-memory-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model3(predictors, label, max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 50, input_length=input_len))\n",
    "    model.add(LSTM(500,return_sequences=True))\n",
    "    model.add(LSTM(500))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['mae', 'acc',perplexity])\n",
    "    model.fit(predictors, label, epochs=50, verbose=1)\n",
    "    model.save('model3.h5')\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96360/96360 [==============================] - 376s 4ms/step - loss: 7.2489 - mean_absolute_error: 2.4915e-04 - acc: 0.0309 - perplexity: 5780.1697\n",
      "Epoch 2/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.1927 - mean_absolute_error: 2.4915e-04 - acc: 0.0318 - perplexity: 5579.3259\n",
      "Epoch 3/50\n",
      "96360/96360 [==============================] - 376s 4ms/step - loss: 7.1914 - mean_absolute_error: 2.4915e-04 - acc: 0.0318 - perplexity: 5551.3724\n",
      "Epoch 4/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.1920 - mean_absolute_error: 2.4916e-04 - acc: 0.0311 - perplexity: 5549.5990\n",
      "Epoch 5/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.1966 - mean_absolute_error: 2.4917e-04 - acc: 0.0306 - perplexity: 5565.8347\n",
      "Epoch 6/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.1966 - mean_absolute_error: 2.4915e-04 - acc: 0.0316 - perplexity: 5574.3256\n",
      "Epoch 7/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2017 - mean_absolute_error: 2.4916e-04 - acc: 0.0312 - perplexity: 5579.6752\n",
      "Epoch 8/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.1972 - mean_absolute_error: 2.4915e-04 - acc: 0.0309 - perplexity: 5581.4123\n",
      "Epoch 9/50\n",
      "96360/96360 [==============================] - 376s 4ms/step - loss: 7.2069 - mean_absolute_error: 2.4917e-04 - acc: 0.0303 - perplexity: 5604.4391\n",
      "Epoch 10/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2026 - mean_absolute_error: 2.4916e-04 - acc: 0.0305 - perplexity: 5601.2950\n",
      "Epoch 11/50\n",
      "96360/96360 [==============================] - 377s 4ms/step - loss: 7.2049 - mean_absolute_error: 2.4916e-04 - acc: 0.0307 - perplexity: 5607.8100\n",
      "Epoch 12/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2063 - mean_absolute_error: 2.4915e-04 - acc: 0.0316 - perplexity: 5623.6259\n",
      "Epoch 13/50\n",
      "96360/96360 [==============================] - 377s 4ms/step - loss: 7.2067 - mean_absolute_error: 2.4915e-04 - acc: 0.0300 - perplexity: 5622.8187\n",
      "Epoch 14/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2077 - mean_absolute_error: 2.4916e-04 - acc: 0.0301 - perplexity: 5624.3050\n",
      "Epoch 15/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2089 - mean_absolute_error: 2.4915e-04 - acc: 0.0314 - perplexity: 5624.7293\n",
      "Epoch 16/50\n",
      "96360/96360 [==============================] - 376s 4ms/step - loss: 7.2069 - mean_absolute_error: 2.4915e-04 - acc: 0.0314 - perplexity: 5645.7203\n",
      "Epoch 17/50\n",
      "96360/96360 [==============================] - 373s 4ms/step - loss: 7.2074 - mean_absolute_error: 2.4915e-04 - acc: 0.0315 - perplexity: 5636.5910\n",
      "Epoch 18/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2063 - mean_absolute_error: 2.4915e-04 - acc: 0.0316 - perplexity: 5646.0230\n",
      "Epoch 19/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2142 - mean_absolute_error: 2.4915e-04 - acc: 0.0309 - perplexity: 5653.3767\n",
      "Epoch 20/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2111 - mean_absolute_error: 2.4915e-04 - acc: 0.0308 - perplexity: 5659.7162\n",
      "Epoch 21/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2115 - mean_absolute_error: 2.4916e-04 - acc: 0.0309 - perplexity: 5655.0346\n",
      "Epoch 22/50\n",
      "96360/96360 [==============================] - 378s 4ms/step - loss: 7.2143 - mean_absolute_error: 2.4916e-04 - acc: 0.0303 - perplexity: 5675.4733\n",
      "Epoch 23/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2113 - mean_absolute_error: 2.4916e-04 - acc: 0.0304 - perplexity: 5676.4196\n",
      "Epoch 24/50\n",
      "96360/96360 [==============================] - 376s 4ms/step - loss: 7.2162 - mean_absolute_error: 2.4915e-04 - acc: 0.0308 - perplexity: 5693.5386\n",
      "Epoch 25/50\n",
      "96360/96360 [==============================] - 376s 4ms/step - loss: 7.2142 - mean_absolute_error: 2.4915e-04 - acc: 0.0314 - perplexity: 5689.2543\n",
      "Epoch 26/50\n",
      "96360/96360 [==============================] - 376s 4ms/step - loss: 7.2155 - mean_absolute_error: 2.4915e-04 - acc: 0.0316 - perplexity: 5685.0574\n",
      "Epoch 27/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2153 - mean_absolute_error: 2.4916e-04 - acc: 0.0306 - perplexity: 5701.6742\n",
      "Epoch 28/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2171 - mean_absolute_error: 2.4915e-04 - acc: 0.0317 - perplexity: 5700.2038\n",
      "Epoch 29/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2212 - mean_absolute_error: 2.4915e-04 - acc: 0.0315 - perplexity: 5719.9458\n",
      "Epoch 30/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2187 - mean_absolute_error: 2.4915e-04 - acc: 0.0321 - perplexity: 5717.1367\n",
      "Epoch 31/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2171 - mean_absolute_error: 2.4914e-04 - acc: 0.0315 - perplexity: 5714.9901\n",
      "Epoch 32/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2190 - mean_absolute_error: 2.4915e-04 - acc: 0.0307 - perplexity: 5730.2379\n",
      "Epoch 33/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2210 - mean_absolute_error: 2.4916e-04 - acc: 0.0307 - perplexity: 5741.7893\n",
      "Epoch 34/50\n",
      "96360/96360 [==============================] - 373s 4ms/step - loss: 7.2220 - mean_absolute_error: 2.4916e-04 - acc: 0.0307 - perplexity: 5728.3744\n",
      "Epoch 35/50\n",
      "96360/96360 [==============================] - 377s 4ms/step - loss: 7.2201 - mean_absolute_error: 2.4916e-04 - acc: 0.0303 - perplexity: 5744.0142\n",
      "Epoch 36/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2196 - mean_absolute_error: 2.4915e-04 - acc: 0.0314 - perplexity: 5760.0727\n",
      "Epoch 37/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2233 - mean_absolute_error: 2.4915e-04 - acc: 0.0311 - perplexity: 5777.0799\n",
      "Epoch 38/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2220 - mean_absolute_error: 2.4916e-04 - acc: 0.0309 - perplexity: 5764.1397\n",
      "Epoch 39/50\n",
      "96360/96360 [==============================] - 373s 4ms/step - loss: 7.2217 - mean_absolute_error: 2.4915e-04 - acc: 0.0304 - perplexity: 5791.4989\n",
      "Epoch 40/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2263 - mean_absolute_error: 2.4917e-04 - acc: 0.0299 - perplexity: 5785.9426\n",
      "Epoch 41/50\n",
      "96360/96360 [==============================] - 373s 4ms/step - loss: 7.2213 - mean_absolute_error: 2.4916e-04 - acc: 0.0306 - perplexity: 5790.1143\n",
      "Epoch 42/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2232 - mean_absolute_error: 2.4915e-04 - acc: 0.0306 - perplexity: 5812.3317\n",
      "Epoch 43/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2233 - mean_absolute_error: 2.4915e-04 - acc: 0.0306 - perplexity: 5809.6346\n",
      "Epoch 44/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2241 - mean_absolute_error: 2.4915e-04 - acc: 0.0312 - perplexity: 5821.9543\n",
      "Epoch 45/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2240 - mean_absolute_error: 2.4915e-04 - acc: 0.0297 - perplexity: 5826.4783\n",
      "Epoch 46/50\n",
      "96360/96360 [==============================] - 373s 4ms/step - loss: 7.2265 - mean_absolute_error: 2.4916e-04 - acc: 0.0307 - perplexity: 5831.9549\n",
      "Epoch 47/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2262 - mean_absolute_error: 2.4914e-04 - acc: 0.0320 - perplexity: 5830.6070\n",
      "Epoch 48/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2247 - mean_absolute_error: 2.4915e-04 - acc: 0.0305 - perplexity: 5837.8529\n",
      "Epoch 49/50\n",
      "96360/96360 [==============================] - 374s 4ms/step - loss: 7.2255 - mean_absolute_error: 2.4916e-04 - acc: 0.0311 - perplexity: 5835.9129\n",
      "Epoch 50/50\n",
      "96360/96360 [==============================] - 375s 4ms/step - loss: 7.2265 - mean_absolute_error: 2.4916e-04 - acc: 0.0314 - perplexity: 5852.7485\n"
     ]
    }
   ],
   "source": [
    "model3 = create_model3(X, Y, max_len, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and\n"
     ]
    }
   ],
   "source": [
    "text3 = generate_text(\"Anne\", 100, max_len, model3)\n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of model3 // stacked LSTM\n",
    "from observation we found that it worst that pick a random word and rearrange them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Help your model to generate a short story \n",
    "\n",
    "**Example** https://medium.com/deep-writing/harry-potter-written-by-artificial-intelligence-8a9431803da6\n",
    "\n",
    "Write your result in a `markdown` cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your short-story from your model (Add your creativity here)\n",
    "Anne was sitting on the yellow chair by the window gazing mournfully out they morning under always then jane had to him up until her face led marilla’s dinner to the end of been led continued to the pond mercy of the hotel and the night at the house she gets good going to be it how got as i like when you are let me oh marilla i’m willing to think i didn’t know they’re myself but those don’t know i’d like have three head ” she said in a here it’s a chair you can come along isn’t it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on Natural language Processing and Language model\n",
    "1. https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e \n",
    "2. https://medium.com/phrasee/neural-text-generation-generating-text-using-conditional-language-models-a37b69c7cd4b\n",
    "3. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "**Music generates by RNN**\n",
    "https://soundcloud.com/optometrist-prime/recurrence-music-written-by-a-recurrent-neural-network\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
